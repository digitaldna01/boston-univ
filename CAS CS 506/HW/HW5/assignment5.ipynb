{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing:\n",
    "- Handle missing values and ensure that all relevant features are properly scaled.\n",
    "- Analyze categorical and numerical variables to determine which are most important for churn prediction.\n",
    "- Perform feature selection or engineering to improve model performance.\n",
    "\n",
    "# Model Building:\n",
    "- Implement K-Nearest Neighbors (KNN) from scratch. Pre-built libraries (e.g., scikit-learn, TensorFlow) for KNN are not allowed.\n",
    "- Split the dataset and train the model to classify customers into churn and non-churn categories.\n",
    "- Explore different values for K and choose the optimal one based on performance metrics.\n",
    "- Tune the model by adjusting hyperparameters such as the distance metric (Euclidean, Manhattan, etc.).\n",
    "\n",
    "# Model Evaluation:\n",
    "- Evaluate the model using metrics such as accuracy, precision, recall, F1-score, area under the ROC curve.\n",
    "- Use cross-validation to ensure the model is not overfitting to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the KNN class\n",
    "class KNN:\n",
    "    def __init__(self, k=3, distance_metric='euclidean', p=2):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.p = p  # For Minkowski distance\n",
    "    \n",
    "    def euclidean_distance(self, X1, X2):\n",
    "        return np.sqrt(np.sum((X1 - X2)**2, axis=1))\n",
    "    \n",
    "    def manhattan_distance(self, X1, X2):\n",
    "        return np.sum(np.abs(X1 - X2), axis=1)\n",
    "\n",
    "    def cosine_distance(self, X1, X2):\n",
    "        dot_product = np.sum(X1 * X2, axis=1)\n",
    "        norm_X1 = np.linalg.norm(X1, axis=1)\n",
    "        norm_X2 = np.linalg.norm(X2)\n",
    "        return 1 - dot_product / (norm_X1 * norm_X2)\n",
    "    \n",
    "    def minkowski_distance(self, point1, point2):\n",
    "        return np.power(np.sum(np.power(np.abs(point1 - point2), self.p)), 1/self.p)\n",
    "\n",
    "    def chebyshev_distance(self, point1, point2):\n",
    "        return np.max(np.abs(point1 - point2))\n",
    "\n",
    "    def compute_distance(self, X1, X2):\n",
    "        if self.distance_metric == \"euclidean\":\n",
    "            return self.euclidean_distance(X1, X2)\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return self.manhattan_distance(X1, X2)\n",
    "        elif self.distance_metric == 'cosine':\n",
    "            return self.cosine_distance(X1, X2)\n",
    "        elif self.distance_metric == 'minkowski':\n",
    "            return self.minkowski_distance(X1, X2)\n",
    "        elif self.distance_metric == 'chebyshev':\n",
    "            return self.chebyshev_distance(X1, X2)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown distance metric: {self.distance_metric}\")\n",
    "\n",
    "    # Use Training data to store the data in KNN Model\n",
    "    def fit(self, X, y):\n",
    "        # TODO: Implement the fit method\n",
    "        self.train_x = np.array(X)\n",
    "        self.train_y = np.array(y)\n",
    "        if (len(self.train_x) != len(self.train_y)):\n",
    "            raise ValueError(f\"Train X and Train Y size differ, Train size: {len(self.train_x)} Test size: {len(self.train_y)}\")\n",
    "        self.train_size = len(self.train_x)\n",
    "        \n",
    "    def n_closest_to(self, X):\n",
    "        distances = self.compute_distance(self.train_x, X)\n",
    "        return np.argsort(distances)[:self.k]\n",
    "    \n",
    "    def majority(self, closest_points):\n",
    "        labels = self.train_y[closest_points]\n",
    "        unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "        return unique_labels[np.argmax(counts)]\n",
    "\n",
    "    # Predict the Class of Test_X data \n",
    "    def predict(self, X_test):\n",
    "        predictions = np.empty(X_test.shape[0], dtype=self.train_y.dtype)\n",
    "        for i, x in enumerate(X_test):\n",
    "            closest_points = self.n_closest_to(x)\n",
    "            predictions[i] = self.majority(closest_points)\n",
    "        return predictions\n",
    "    \n",
    "    def predict_proba(self, X_test):\n",
    "        probabilities = np.empty(X_test.shape[0])\n",
    "        for i, x in enumerate(X_test):\n",
    "            closest_points = self.n_closest_to(x)\n",
    "            closest_labels = self.train_y[closest_points]\n",
    "            probabilities[i] = np.mean(closest_labels)\n",
    "        return probabilities\n",
    "\n",
    "class SimpleEnsembleKNN:\n",
    "    def __init__(self, n_models=5):\n",
    "        self.models = [KNN(k=np.random.randint(3, 20)) for _ in range(n_models)]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for model in self.models:\n",
    "            model.fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = np.array([model.predict(X) for model in self.models])\n",
    "        return np.round(np.mean(predictions, axis=0)).astype(int)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        probas = np.array([model.predict_proba(X) for model in self.models])\n",
    "        return np.mean(probas, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_features(X):\n",
    "    X['Age_squared'] = X['Age'] ** 2\n",
    "    X['Balance_log'] = np.log1p(X['Balance'])\n",
    "    X['CreditScore_scaled'] = X['CreditScore'] / 1000\n",
    "    X['Age_CreditScore_interaction'] = X['Age'] * X['CreditScore_scaled']\n",
    "    return X\n",
    "\n",
    "def simple_feature_selection(X, y, k=5):\n",
    "    y_series = pd.Series(y) if isinstance(y, np.ndarray) else y\n",
    "    correlations = X.corrwith(y_series).abs().sort_values(ascending=False)\n",
    "    selected_features = correlations.head(k).index\n",
    "    return X[selected_features], selected_features\n",
    "\n",
    "def svd_reduction(X, X_test, n_components=2):\n",
    "    # X의 SVD 수행\n",
    "    U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "    \n",
    "    # 처음 n_components 개의 특이값과 특이벡터만 사용\n",
    "    U_reduced = U[:, :n_components]\n",
    "    s_reduced = s[:n_components]\n",
    "    Vt_reduced = Vt[:n_components, :]\n",
    "    \n",
    "    # 축소된 특징 공간으로 데이터 변환\n",
    "    X_reduced = np.dot(U_reduced, np.diag(s_reduced))\n",
    "    \n",
    "    # 테스트 데이터를 같은 특징 공간으로 변환\n",
    "    X_test_reduced = np.dot(X_test, Vt_reduced.T)\n",
    "    \n",
    "    return X_reduced, X_test_reduced\n",
    "# Manually implementing one-hot encoding\n",
    "def manual_one_hot_encoding(df, column):\n",
    "    if column not in df.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in the dataframe\")\n",
    "    \n",
    "    unique_values = df[column].unique()  # Find unique values in the column\n",
    "    \n",
    "    for unique_value in unique_values:\n",
    "        new_column_name = f\"{column}_{unique_value}\"\n",
    "        df[new_column_name] = df[column].apply(lambda x: 1 if x == unique_value else 0)\n",
    "    \n",
    "    df = df.drop(column, axis=1)  # Drop the original column\n",
    "    return df\n",
    "\n",
    "# Function to apply manual feature scaling\n",
    "def manual_standard_scaler(df, column):\n",
    "    if column not in df.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in the dataframe\")\n",
    "    \n",
    "    mean = np.mean(df[column])\n",
    "    std = np.std(df[column])\n",
    "    \n",
    "    # Apply the standardization formula\n",
    "    df[column] = (df[column] - mean) / std\n",
    "    return df\n",
    "\n",
    "def preprocess_common(data, y=None, selected_features=None):\n",
    "    data = data.drop(['id', 'CustomerId', 'Surname'], axis=1)\n",
    "    data = manual_one_hot_encoding(data, 'Geography')\n",
    "    data = manual_one_hot_encoding(data, 'Gender')\n",
    "    \n",
    "    data = create_new_features(data)\n",
    "    \n",
    "    if y is not None and selected_features is None:\n",
    "        data, selected_features = simple_feature_selection(data, y)\n",
    "    elif selected_features is not None:\n",
    "        data = data[selected_features]\n",
    "    \n",
    "    for column in ['CreditScore', 'Age', 'Balance', 'CreditScore_scaled']:\n",
    "        if column in data.columns:\n",
    "            data = manual_standard_scaler(data, column)\n",
    "    \n",
    "    return data.to_numpy(), selected_features\n",
    "\n",
    "def preprocess_data(train_path, test_path):\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    X_test = pd.read_csv(test_path)\n",
    "    \n",
    "    y = train_data['Exited']  # Keep y as a Pandas Series\n",
    "    X, selected_features = preprocess_common(train_data.drop(['Exited'], axis=1), y)\n",
    "    X_test, _ = preprocess_common(X_test, selected_features=selected_features)\n",
    "    \n",
    "    return X, y.to_numpy(), X_test\n",
    "\n",
    "def preprocess_data_svd(train_path, test_path, n_components=2):\n",
    "    X, y, X_test = preprocess_data(train_path, test_path)\n",
    "    X_reduced, X_test_reduced = svd_reduction(X, X_test, n_components=n_components)\n",
    "    return X_reduced, y, X_test_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "    confusion_matrix = np.zeros((2, 2))\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            confusion_matrix[i, j] = np.sum((y_true == i) & (y_pred == j))\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix.ravel()\n",
    "    \n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def compute_roc_auc(y_true, y_scores):\n",
    "    sorted_indices = np.argsort(y_scores)[::-1]\n",
    "    y_true = y_true[sorted_indices]\n",
    "    \n",
    "    tp_cumsum = np.cumsum(y_true)\n",
    "    fp_cumsum = np.cumsum(1 - y_true)\n",
    "    \n",
    "    tpr = tp_cumsum / np.sum(y_true)\n",
    "    fpr = fp_cumsum / np.sum(1 - y_true)\n",
    "    \n",
    "    # AUC 계산\n",
    "    auc = np.trapz(tpr, fpr)\n",
    "    \n",
    "    return auc\n",
    "\n",
    "# Define cross-validation function\n",
    "def cross_validate(X, y, knn, n_splits=5):\n",
    "    fold_size = len(X) // n_splits\n",
    "    metrics = {\n",
    "        'accuracy': [], 'precision': [], 'recall': [], 'f1_score': [], 'roc_auc': []\n",
    "    }\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        start = i * fold_size\n",
    "        end = start + fold_size if i < n_splits - 1 else len(X)\n",
    "        \n",
    "        X_train = np.concatenate([X[:start], X[end:]])\n",
    "        y_train = np.concatenate([y[:start], y[end:]])\n",
    "        X_test = X[start:end]\n",
    "        y_test = y[start:end]\n",
    "        \n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        y_scores = knn.predict_proba(X_test)\n",
    "\n",
    "        accuracy, precision, recall, f1 = compute_metrics(y_test, y_pred)\n",
    "        roc_auc = compute_roc_auc(y_test, y_scores)\n",
    "\n",
    "        for metric, value in zip(metrics.keys(), [accuracy, precision, recall, f1, roc_auc]):\n",
    "            metrics[metric].append(value)\n",
    "\n",
    "    return {metric: np.mean(values) for metric, values in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: {'accuracy': 0.8586666666666666, 'precision': 0.7185034965841597, 'recall': 0.4959334840734737, 'f1_score': 0.5864332190375403, 'roc_auc': 0.8412420520662793}\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
    "X\n",
    "# Create and evaluate model\n",
    "knn = KNN(k=5, distance_metric='cosine')\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_validate(X, y, knn)\n",
    "\n",
    "print(\"Cross-validation scores:\", cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: {'accuracy': 0.7716000000000001, 'precision': 0.2668292377308332, 'recall': 0.0725209283940105, 'f1_score': 0.11375525816834915, 'roc_auc': -0.5335686112592383}\n",
      "k: 3, distance_metric: euclidean, Score: {'accuracy': 0.7558666666666667, 'precision': 0.28402735013687613, 'recall': 0.13439466270438308, 'f1_score': 0.18205683315625296, 'roc_auc': -0.5442510683978025}\n",
      "\n",
      "k: 3, distance_metric: manhattan, Score: {'accuracy': 0.7641333333333333, 'precision': 0.3159710056110793, 'recall': 0.14201601155555837, 'f1_score': 0.19571620765256964, 'roc_auc': -0.5759630274095184}\n",
      "\n",
      "k: 3, distance_metric: chebyshev, Score: {'accuracy': 0.7461333333333333, 'precision': 0.24686502150063233, 'recall': 0.1231219750833908, 'f1_score': 0.1637603948192148, 'roc_auc': -0.5218395882741795}\n",
      "\n",
      "k: 5, distance_metric: euclidean, Score: {'accuracy': 0.7716000000000001, 'precision': 0.2668292377308332, 'recall': 0.0725209283940105, 'f1_score': 0.11375525816834915, 'roc_auc': -0.5335686112592383}\n",
      "\n",
      "k: 5, distance_metric: manhattan, Score: {'accuracy': 0.7776666666666666, 'precision': 0.3139266394349004, 'recall': 0.08179003823869999, 'f1_score': 0.12957165853385053, 'roc_auc': -0.5683638367502002}\n",
      "\n",
      "k: 5, distance_metric: chebyshev, Score: {'accuracy': 0.7672, 'precision': 0.2419923762032346, 'recall': 0.0701820481603429, 'f1_score': 0.10841908243037417, 'roc_auc': -0.515598400166377}\n",
      "\n",
      "k: 10, distance_metric: euclidean, Score: {'accuracy': 0.7896666666666666, 'precision': 0.300227754107368, 'recall': 0.029643818021698985, 'f1_score': 0.05390674034433991, 'roc_auc': -0.5225209387375751}\n",
      "\n",
      "k: 10, distance_metric: manhattan, Score: {'accuracy': 0.7934666666666665, 'precision': 0.3920789876234182, 'recall': 0.03431560393025244, 'f1_score': 0.06293605820914362, 'roc_auc': -0.5550105600424503}\n",
      "\n",
      "k: 10, distance_metric: chebyshev, Score: {'accuracy': 0.7882666666666667, 'precision': 0.2778416613571757, 'recall': 0.02833756613405175, 'f1_score': 0.05131209380219535, 'roc_auc': -0.5090372063467575}\n",
      "\n",
      "k: 15, distance_metric: euclidean, Score: {'accuracy': 0.7951333333333334, 'precision': 0.245793489809717, 'recall': 0.005308378989874597, 'f1_score': 0.010324192395163943, 'roc_auc': -0.5150099232715066}\n",
      "\n",
      "k: 15, distance_metric: manhattan, Score: {'accuracy': 0.7956000000000001, 'precision': 0.27612010796221326, 'recall': 0.0059527880257092165, 'f1_score': 0.011585921897199262, 'roc_auc': -0.540529399028929}\n",
      "\n",
      "k: 15, distance_metric: chebyshev, Score: {'accuracy': 0.7943333333333333, 'precision': 0.16904761904761903, 'recall': 0.004679853661125823, 'f1_score': 0.009009183449483397, 'roc_auc': -0.505384334272492}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
    "\n",
    "# Create and evaluate model\n",
    "knn = KNN(k=5, distance_metric='euclidean')\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_validate(X, y, knn)\n",
    "\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "\n",
    "def compute_model_score(X, y, k, distance_metric):\n",
    "    # KNN 모델 생성 및 평가\n",
    "    knn = KNN(k=k, distance_metric=distance_metric)\n",
    "    scores = cross_validate(X, y, knn)  # 사용자 정의 cross-validation 함수\n",
    "    return scores # 평균 점수 반환\n",
    "\n",
    "# TODO: hyperparamters tuning\n",
    "k_values = [3, 5, 10, 15]\n",
    "distance_metrics = ['euclidean', 'manhattan']\n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "for k in k_values:\n",
    "    for distance_metric in distance_metrics:\n",
    "        score = compute_model_score(X, y, k, distance_metric)\n",
    "        print(f\"k: {k}, distance_metric: {distance_metric}, Score: {score}\\n\")\n",
    "\n",
    "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
    "# knn = ...\n",
    "# knn.fit(X, y)\n",
    "# test_predictions = knn.predict(X_test)\n",
    "\n",
    "# # Save test predictions\n",
    "# pd.DataFrame({'id': pd.read_csv('/path/of/test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 3, distance_metric: euclidean, ROC AUC: 0.8104\n",
      "k: 3, distance_metric: manhattan, ROC AUC: 0.8121\n",
      "k: 3, distance_metric: cosine, ROC AUC: 0.8227\n",
      "k: 3, distance_metric: minkowski, p: 1, ROC AUC: 0.4998\n",
      "k: 3, distance_metric: minkowski, p: 2, ROC AUC: 0.4998\n",
      "k: 3, distance_metric: minkowski, p: 3, ROC AUC: 0.4998\n",
      "k: 3, distance_metric: chebyshev, ROC AUC: 0.4998\n",
      "k: 5, distance_metric: euclidean, ROC AUC: 0.8329\n",
      "k: 5, distance_metric: manhattan, ROC AUC: 0.8356\n",
      "k: 5, distance_metric: cosine, ROC AUC: 0.8476\n",
      "k: 5, distance_metric: minkowski, p: 1, ROC AUC: 0.4998\n",
      "k: 5, distance_metric: minkowski, p: 2, ROC AUC: 0.4998\n",
      "k: 5, distance_metric: minkowski, p: 3, ROC AUC: 0.4998\n",
      "k: 5, distance_metric: chebyshev, ROC AUC: 0.4998\n",
      "k: 7, distance_metric: euclidean, ROC AUC: 0.8450\n",
      "k: 7, distance_metric: manhattan, ROC AUC: 0.8491\n",
      "k: 7, distance_metric: cosine, ROC AUC: 0.8619\n",
      "k: 7, distance_metric: minkowski, p: 1, ROC AUC: 0.4998\n",
      "k: 7, distance_metric: minkowski, p: 2, ROC AUC: 0.4998\n",
      "k: 7, distance_metric: minkowski, p: 3, ROC AUC: 0.4998\n",
      "k: 7, distance_metric: chebyshev, ROC AUC: 0.4998\n",
      "k: 10, distance_metric: euclidean, ROC AUC: 0.8574\n",
      "k: 10, distance_metric: manhattan, ROC AUC: 0.8607\n",
      "k: 10, distance_metric: cosine, ROC AUC: 0.8710\n",
      "k: 10, distance_metric: minkowski, p: 1, ROC AUC: 0.4998\n",
      "k: 10, distance_metric: minkowski, p: 2, ROC AUC: 0.4998\n",
      "k: 10, distance_metric: minkowski, p: 3, ROC AUC: 0.4998\n",
      "k: 10, distance_metric: chebyshev, ROC AUC: 0.4998\n",
      "k: 15, distance_metric: euclidean, ROC AUC: 0.8647\n",
      "k: 15, distance_metric: manhattan, ROC AUC: 0.8699\n",
      "k: 15, distance_metric: cosine, ROC AUC: 0.8784\n",
      "k: 15, distance_metric: minkowski, p: 1, ROC AUC: 0.4998\n",
      "k: 15, distance_metric: minkowski, p: 2, ROC AUC: 0.4998\n",
      "k: 15, distance_metric: minkowski, p: 3, ROC AUC: 0.4998\n",
      "k: 15, distance_metric: chebyshev, ROC AUC: 0.4998\n",
      "k: 20, distance_metric: euclidean, ROC AUC: 0.8686\n",
      "k: 20, distance_metric: manhattan, ROC AUC: 0.8736\n",
      "k: 20, distance_metric: cosine, ROC AUC: 0.8811\n",
      "k: 20, distance_metric: minkowski, p: 1, ROC AUC: 0.4998\n",
      "k: 20, distance_metric: minkowski, p: 2, ROC AUC: 0.4998\n",
      "k: 20, distance_metric: minkowski, p: 3, ROC AUC: 0.4998\n",
      "k: 20, distance_metric: chebyshev, ROC AUC: 0.4998\n",
      "\n",
      "Best Parameters:\n",
      "k: 20\n",
      "Best Distance Metric: cosine\n",
      "Best ROC AUC Score: 0.8811\n",
      "\n",
      "Top 5 Models:\n",
      "     k distance_metric   p   roc_auc\n",
      "37  20          cosine NaN  0.881057\n",
      "30  15          cosine NaN  0.878405\n",
      "36  20       manhattan NaN  0.873623\n",
      "23  10          cosine NaN  0.870954\n",
      "29  15       manhattan NaN  0.869868\n",
      "\n",
      "Final Model Performance:\n",
      "accuracy: 0.8647\n",
      "precision: 0.7309\n",
      "recall: 0.5240\n",
      "f1_score: 0.6102\n",
      "roc_auc: 0.8811\n",
      "\n",
      "Complete Predictions\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
    "\n",
    "def compute_model_score(X, y, k, distance_metric, p=2):\n",
    "    knn = KNN(k=k, distance_metric=distance_metric, p=p)\n",
    "    scores = cross_validate(X, y, knn)\n",
    "    return scores['roc_auc']\n",
    "\n",
    "# Hyperparameters tuning\n",
    "k_values = [3, 5, 7, 10, 15, 20]\n",
    "distance_metrics = ['euclidean', 'manhattan', 'cosine', 'minkowski', 'chebyshev']\n",
    "p_values = [1, 2, 3]  # For Minkowski distance\n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "results = []\n",
    "\n",
    "# Grid search\n",
    "for k in k_values:\n",
    "    for distance_metric in distance_metrics:\n",
    "        if distance_metric == 'minkowski':\n",
    "            for p in p_values:\n",
    "                score = compute_model_score(X, y, k, distance_metric, p)\n",
    "                results.append({\n",
    "                    'k': k,\n",
    "                    'distance_metric': distance_metric,\n",
    "                    'p': p,\n",
    "                    'roc_auc': score\n",
    "                })\n",
    "                print(f\"k: {k}, distance_metric: {distance_metric}, p: {p}, ROC AUC: {score:.4f}\")\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_params = {'k': k, 'distance_metric': distance_metric, 'p': p}\n",
    "        else:\n",
    "            score = compute_model_score(X, y, k, distance_metric)\n",
    "            results.append({\n",
    "                'k': k,\n",
    "                'distance_metric': distance_metric,\n",
    "                'p': None,\n",
    "                'roc_auc': score\n",
    "            })\n",
    "            print(f\"k: {k}, distance_metric: {distance_metric}, ROC AUC: {score:.4f}\")\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = {'k': k, 'distance_metric': distance_metric, 'p': None}\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(f\"k: {best_params['k']}\")\n",
    "print(f\"Best Distance Metric: {best_params['distance_metric']}\")\n",
    "print(f\"Best ROC AUC Score: {best_score:.4f}\")\n",
    "\n",
    "# Convert results to a DataFrame and sort by ROC AUC\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('roc_auc', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Models:\")\n",
    "print(results_df.head())\n",
    "\n",
    "# Final Model\n",
    "best_knn = KNN(k=best_params['k'], distance_metric=best_params['distance_metric'])\n",
    "final_scores = cross_validate(X, y, best_knn)\n",
    "\n",
    "print(\"\\nFinal Model Performance:\")\n",
    "for metric, score in final_scores.items():\n",
    "    print(f\"{metric}: {score:.4f}\")\n",
    "\n",
    "# Test Data Prediction\n",
    "best_knn.fit(X, y)\n",
    "test_predictions = best_knn.predict(X_test)\n",
    "test_probabilities = best_knn.predict_proba(X_test)\n",
    "\n",
    "print(\"\\nComplete Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
    "# Load and preprocess data\n",
    "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
    "\n",
    "knn = KNN(k=20, distance_metric='manhattan')\n",
    "knn.fit(X, y)\n",
    "test_predictions = knn.predict_proba(X_test)\n",
    "\n",
    "# # Save test predictions\n",
    "pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
