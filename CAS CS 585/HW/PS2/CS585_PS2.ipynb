{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgi74o4Dim3s"
      },
      "source": [
        "# CS 585 Problem Set 2 (Total points: 95)\n",
        "\n",
        "Assignment adapted from Svetlana Lazebnik.\n",
        "\n",
        "**Instructions**\n",
        "1.   Assignment is due at 11:59 PM on Tuesday March 04 2025.\n",
        "2.   Submission instructions:\n",
        "\n",
        "     A. A single .pdf report that contains your work for Q1 and Q2. You can either type out your responses in LaTeX or google document. Lastly, please convert your work into a PDF.\n",
        "\n",
        "       The PDF file should be submitted to Gradescope under PS2. Please tag the reponses in your PDF with the Gradescope questions outline as described in Submitting an Assignment.\n",
        "\n",
        "     B. You also need to submit your code in the form of a single .py file in the same directory. You can convert this notebook to Python code by downloading the .ipynb file as Python(.py). Code should also be submitted to Gradescope under PS2-Code. Not submitting your code will lead to a loss of 100% of the points for implementation.\n",
        "\n",
        "     C. Both Q1 and Q2 require you to evaluate your implemented models on held-out test data. You will need to submit the generated outputs (\"Q1_label_predictions.npy\" and \"Q2_surface_predictions.npy\") in the PS2-Code directory as well.\n",
        "\n",
        "     D. We reserve the right to take off points for not following submission instructions. In particular, please tag the reponses in your PDF with the Gradescope questions outline as described in [Submitting an Assignment](https://www.youtube.com/watch?v=u-pK4GzpId0).\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjyxZRoJjkIM"
      },
      "source": [
        "#**Q1: Cifar-10 class predictions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWhrmhqVCyGH"
      },
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "This will allow the Colab machine to access Google Drive folders by mounting the drive on the machine. You may be asked to copy and paste an authentication code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wv2oKmF9AJtI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKGxaMcmP_Et"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qs04PPwDOFy"
      },
      "source": [
        "# Change directory to allow imports\n",
        "\n",
        "\n",
        "As noted above, you should create a Google Drive folder to hold all your assignment files. You will need to add this code to the top of any python notebook you run to be able to import python files from your drive assignment folder (you should change the file path below to be your own assignment folder)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA2-UyfpEc9O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if not os.path.exists(\"/content/gdrive/My Drive/Colab Notebooks/CS_585_PS2\"):\n",
        "    os.makedirs(\"/content/gdrive/My Drive/Colab Notebooks/CS_585_PS2\")\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/CS_585_PS2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyRCWAIyRHWc"
      },
      "outputs": [],
      "source": [
        "!ls # Check if this is your PS2 folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDU5aVgR9QBx"
      },
      "source": [
        "# Set up GPU and PyTorch\n",
        "\n",
        "First, ensure that your notebook on Colaboratory is set up to use GPU. After opening the notebook on Colaboratory, go to Edit>Notebook settings, select Python 3 under \"Runtime type,\" select GPU under \"Hardware accelerator,\" and save.\n",
        "\n",
        "Next, install PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjbQtzKT9Uc2"
      },
      "outputs": [],
      "source": [
        "!pip3 install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_BekZYY9Vzx"
      },
      "source": [
        "Make sure that pytorch is installed and works with GPU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TXSJWQa9efx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "a = torch.Tensor([1]).cuda()\n",
        "print(a)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEeRNsCjRXZK"
      },
      "outputs": [],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlyCnvf6WzjR"
      },
      "outputs": [],
      "source": [
        "# imports and useful functions\n",
        "\n",
        "from __future__ import print_function\n",
        "from PIL import Image\n",
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "import sys\n",
        "if sys.version_info[0] == 2:\n",
        "    import cPickle as pickle\n",
        "else:\n",
        "    import pickle\n",
        "\n",
        "import torch.utils.data as data\n",
        "from torchvision.datasets.utils import download_url, check_integrity\n",
        "import copy\n",
        "import csv\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os.path\n",
        "from tqdm.notebook import tqdm\n",
        "import sys\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "np.random.seed(111)\n",
        "torch.cuda.manual_seed_all(111)\n",
        "torch.manual_seed(111)\n",
        "\n",
        "\n",
        "class CIFAR10Test(torchvision.datasets.VisionDataset):\n",
        "    def __init__(self, root, transform=None,\n",
        "    ):\n",
        "        super(CIFAR10Test, self).__init__(root, transform=transform)\n",
        "\n",
        "        image_filename = os.path.join(root, 'cifar10_test_images.npy')\n",
        "        images = np.load(image_filename)\n",
        "\n",
        "        assert len(images.shape) == 4\n",
        "        assert images.shape[0] == 2000\n",
        "        assert images.shape[1] == 32\n",
        "        assert images.shape[2] == 32\n",
        "        assert images.shape[3] == 3\n",
        "\n",
        "        self.data = images\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = self.data[index]\n",
        "\n",
        "        # doing this so that it is consistent with all other datasets\n",
        "        # to return a PIL Image\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def calculate_accuracy(dataloader, model, is_gpu):\n",
        "    \"\"\" Util function to calculate val set accuracy,\n",
        "    both overall and per class accuracy\n",
        "    Args:\n",
        "        dataloader (torch.utils.data.DataLoader): val set \n",
        "        is_gpu (bool): whether to run on GPU\n",
        "    Returns:\n",
        "        tuple: (overall accuracy, class level accuracy)\n",
        "    \"\"\"    \n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "    predictions = []\n",
        "\n",
        "    class_correct = list(0. for i in range(TOTAL_CLASSES))\n",
        "    class_total = list(0. for i in range(TOTAL_CLASSES))\n",
        "\n",
        "    # Check out why .eval() is important!\n",
        "    # https://discuss.pytorch.org/t/model-train-and-model-eval-vs-model-and-model-eval/5744/2\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for data in dataloader:\n",
        "          images, labels = data\n",
        "          if is_gpu:\n",
        "              images = images.cuda()\n",
        "              labels = labels.cuda()\n",
        "          outputs = model(Variable(images))\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          predictions.extend(list(predicted.cpu().numpy()))\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum()\n",
        "\n",
        "          c = (predicted == labels).squeeze()\n",
        "          for i in range(len(labels)):\n",
        "              label = labels[i]\n",
        "              class_correct[label] += c[i].cpu()\n",
        "              class_total[label] += 1\n",
        "\n",
        "    class_accuracy = 100 * np.divide(class_correct, class_total)\n",
        "    return 100*correct/total, class_accuracy\n",
        "\n",
        "\n",
        "def run_secret_test(dataloader, model, is_gpu):\n",
        "    predictions = []\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for images in dataloader:\n",
        "          if is_gpu:\n",
        "              images = images.cuda()\n",
        "          outputs = model(Variable(images))\n",
        "          predicted = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "          predictions.extend(list(predicted))\n",
        "        \n",
        "    return predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpFMv7HtcII4"
      },
      "source": [
        "\n",
        "Training an image classifier\n",
        "----------------------------\n",
        "\n",
        "We will do the following steps in order:\n",
        "\n",
        "1. Load the randomized CIFAR10 training, validation and test datasets using\n",
        "   torchvision. Use torchvision.transforms to apply transforms on the\n",
        "   dataset.\n",
        "2. Define a Convolution Neural Network - BaseNet\n",
        "3. Define a loss function and optimizer\n",
        "4. Train the network on training data and check performance on val set.\n",
        "   Plot train loss and validation accuracies.\n",
        "5. Try the network on test data and create .npy file for submission to Gradescope"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t54-B8QwSGaS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld6juH34dWWq"
      },
      "outputs": [],
      "source": [
        "# <<TODO>>: Based on the val set performance, decide how many\n",
        "# epochs are apt for your model.\n",
        "# ---------\n",
        "EPOCHS = 15\n",
        "# ---------\n",
        "\n",
        "IS_GPU = True\n",
        "TEST_BS = 256\n",
        "TOTAL_CLASSES = 10\n",
        "TRAIN_BS = 32\n",
        "PATH_TO_CIFAR10 = \"data/cifar10/\"\n",
        "PATH_TO_CIFAR10_TEST = \"/content/gdrive/MyDrive/Colab_Notebooks/CS_585_PS2/data/cifar10/cifar10-test\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq2qOUaJeAWJ"
      },
      "source": [
        "1.**Loading CIFAR-10**\n",
        "\n",
        "We will load the CIFAR-10 dataset with builtin dataset loader from Torchvision. We also created our own train, validation and test splits. You can download them using this link: https://drive.google.com/drive/folders/1qmfLQ8hso5qrN9kyobmKKiCl0PWBdLhK?usp=sharing . Upload the file to colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gttVqAi8mKPm"
      },
      "outputs": [],
      "source": [
        "!unzip -qqo /content/cifar10_splits.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2UcDZmtdfq3"
      },
      "outputs": [],
      "source": [
        "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "# Using transforms.ToTensor(), transform them to Tensors of normalized range\n",
        "# [-1, 1].\n",
        "\n",
        "\n",
        "# <<TODO#1>> Use transforms.Normalize() with the right parameters to \n",
        "# make the data well conditioned (zero mean, std dev=1) for improved training.\n",
        "# <<TODO#2>> Try using transforms.RandomCrop() and/or transforms.RandomHorizontalFlip()\n",
        "# to augment training data.\n",
        "# After your edits, make sure that test_transform should have the same data\n",
        "# normalization parameters as train_transform\n",
        "# You shouldn't have any data augmentation in test_transform (val or test data is never augmented).\n",
        "# ---------------------\n",
        "train_transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "test_transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "# ---------------------\n",
        "\n",
        "#DO NOT CHANGE any line below\n",
        "train_dataset = torchvision.datasets.CIFAR10(root=PATH_TO_CIFAR10, train=True, download=True, transform=train_transform)\n",
        "val_dataset = torchvision.datasets.CIFAR10(root=PATH_TO_CIFAR10, train=False, download=False, transform=test_transform)\n",
        "test_dataset = CIFAR10Test(root=PATH_TO_CIFAR10_TEST, transform=test_transform)\n",
        "\n",
        "val_dataset.data = np.load(\"cifar10_splits/cifar10_val_images.npy\")\n",
        "val_dataset.targets = np.load(\"cifar10_splits/cifar10_val_labels.npy\")\n",
        "test_dataset.data = np.load(\"cifar10_splits/cifar10_test_images.npy\")\n",
        "\n",
        "print(\"train_dataset data shape: \", np.array(train_dataset.data).shape)\n",
        "print(\"train_dataset labels shape: \", np.array(train_dataset.targets).shape)\n",
        "print()\n",
        "print(\"val_dataset data shape: \", np.array(val_dataset.data).shape)\n",
        "print(\"val_dataset labels shape:\", np.array(val_dataset.targets).shape)\n",
        "\n",
        "# check for Dataloader function: https://pytorch.org/docs/stable/data.html\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=TRAIN_BS, shuffle=True, num_workers=2, drop_last=True)  #DO NOT CHANGE\n",
        "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=TEST_BS, shuffle=False, num_workers=2, drop_last=False)\n",
        "#testloader = torch.utils.data.DataLoader(test_dataset, batch_size=TEST_BS, shuffle=False, num_workers=2, drop_last=False) #DO NOT CHANGE\n",
        "\n",
        "# The 10 classes for FashionMNIST\n",
        "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk1421Bpleek"
      },
      "source": [
        "2.**Visualize CIFAR-10**\n",
        "\n",
        "We will visualize some random images from the CIFAR-10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lo4hAqbSS3BW"
      },
      "outputs": [],
      "source": [
        "# Let us show some of the training images, for fun.\n",
        "# functions to show an image\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[:16]))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(16)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gVdM0Cwlo6N"
      },
      "source": [
        "3.**Define a Convolution Neural Network**\n",
        "\n",
        "Implement the BaseNet exactly. BaseNet consists of two convolutional modules (conv-relu-maxpool) and two linear layers. The precise architecture is defined below:\n",
        "\n",
        "| Layer No.   | Layer Type  | Kernel Size | Input Dim   | Output Dim  | Input Channels | Output Channels |\n",
        "    | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- |\n",
        "    | 1 | conv2d | 5 | 32 | 28 | 3 | 6 |\n",
        "    | 2 | relu | - | 28 | 28 | 6 | 6 |\n",
        "    | 3 | maxpool2d | 2 | 28 | 14 | 6 | 6 |\n",
        "    | 4 | conv2d | 5 | 14 | 10 | 6 | 16 |\n",
        "    | 5 | relu | - | 10 | 10 | 16 | 16 |\n",
        "    | 6 | maxpool2d | 2 | 10 | 5 | 16 | 16 |\n",
        "    | 7 | linear | - | 1 | 1 | 400 | 200 |\n",
        "    | 8 | relu | - | 1 | 1 | 200 | 200 |\n",
        "    | 9 | linear | - | 1 | 1 | 200 | 10 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b_fBznndp4W"
      },
      "outputs": [],
      "source": [
        "########################################################################\n",
        "# We provide a basic network that you should understand, run and\n",
        "# eventually improve\n",
        "# <<TODO>> Add more conv layers\n",
        "# <<TODO>> Add more fully connected (fc) layers\n",
        "# <<TODO>> Add regularization layers like Batchnorm.\n",
        "#          nn.BatchNorm2d after conv layers:\n",
        "#          http://pytorch.org/docs/master/nn.html#batchnorm2d\n",
        "#          nn.BatchNorm1d after fc layers:\n",
        "#          http://pytorch.org/docs/master/nn.html#batchnorm1d\n",
        "# This is a good resource for developing a CNN for classification:\n",
        "# http://cs231n.github.io/convolutional-networks/#layers\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BaseNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseNet, self).__init__()\n",
        "        \n",
        "        # TODO: define your model here\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # TODO: define your model here\n",
        "        \n",
        "        return x\n",
        "\n",
        "# Create an instance of the nn.module class defined above:\n",
        "net = BaseNet()\n",
        "\n",
        "# Test your BaseNet with some random input\n",
        "dummy_input = torch.rand((1, 3, 32, 32))\n",
        "output = net(dummy_input)\n",
        "assert output.shape == torch.Size([1, 10])\n",
        "\n",
        "# For training on GPU, we need to transfer net and data onto the GPU\n",
        "# http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-on-gpu\n",
        "if IS_GPU:\n",
        "    net = net.cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTtJrAGjXElg"
      },
      "outputs": [],
      "source": [
        "# TODO: paste output in your report\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ6wlwMymr2m"
      },
      "source": [
        "4.**Define a loss function and optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAZjIcLOdp-W"
      },
      "outputs": [],
      "source": [
        "########################################################################\n",
        "# Here we use Cross-Entropy loss and SGD with momentum.\n",
        "# The CrossEntropyLoss criterion already includes softmax within its\n",
        "# implementation. That's why we don't use a softmax in our model\n",
        "# definition.\n",
        "\n",
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Tune the learning rate.\n",
        "# See whether the momentum and weight decay is useful or not\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bZXUK5Dmv12"
      },
      "source": [
        "5.**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ku7eF366dyUP"
      },
      "outputs": [],
      "source": [
        "########################################################################\n",
        "# We simply have to loop over our data iterator, and feed the inputs to the\n",
        "# network and optimize. We evaluate the validation accuracy at each\n",
        "# epoch and plot these values over the number of epochs\n",
        "# Nothing to change here\n",
        "# -----------------------------\n",
        "plt.ioff()\n",
        "fig = plt.figure()\n",
        "train_loss_over_epochs = []\n",
        "val_accuracy_over_epochs = []\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS), total=EPOCHS):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        if IS_GPU:\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    # Normalizing the loss by the total number of train batches\n",
        "    running_loss/=len(trainloader)\n",
        "    print('[%d] loss: %.3f' %\n",
        "          (epoch + 1, running_loss))\n",
        "\n",
        "    # Scale of 0.0 to 100.0\n",
        "    # Calculate validation set accuracy of the existing model\n",
        "    val_accuracy, val_classwise_accuracy = \\\n",
        "        calculate_accuracy(valloader, net, IS_GPU)\n",
        "    print('Accuracy of the network on the val images: %d %%' % (val_accuracy))\n",
        "\n",
        "    # # Optionally print classwise accuracies\n",
        "    # for c_i in range(TOTAL_CLASSES):\n",
        "    #     print('Accuracy of %5s : %2d %%' % (\n",
        "    #         classes[c_i], 100 * val_classwise_accuracy[c_i]))\n",
        "\n",
        "    train_loss_over_epochs.append(running_loss)\n",
        "    val_accuracy_over_epochs.append(val_accuracy.cpu())\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "# Plot train loss over epochs and val set accuracy over epochs\n",
        "# Nothing to change here\n",
        "# -------------\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.ylabel('Train loss')\n",
        "plt.plot(np.arange(EPOCHS), train_loss_over_epochs, 'k-')\n",
        "plt.title('train loss and val accuracy')\n",
        "plt.xticks(np.arange(EPOCHS, dtype=int))\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(np.arange(EPOCHS), val_accuracy_over_epochs, 'b-')\n",
        "plt.ylabel('Val accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.xticks(np.arange(EPOCHS, dtype=int))\n",
        "plt.grid(True)\n",
        "plt.savefig(\"mp4_q1_plot.png\")\n",
        "plt.close(fig)\n",
        "print('Finished Training')\n",
        "# -------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQUWyGBcm0FG"
      },
      "source": [
        "6.**Evaluate the validation accuracy of your final model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1GE8t3mRdy9"
      },
      "outputs": [],
      "source": [
        "val_accuracy, val_classwise_accuracy = \\\n",
        "        calculate_accuracy(valloader, net, IS_GPU)\n",
        "print('Accuracy of the final network on the val images: %.1f %%' % (val_accuracy))\n",
        "\n",
        "# Optionally print classwise accuracies\n",
        "for c_i in range(TOTAL_CLASSES):\n",
        "    print('Accuracy of %5s : %.1f %%' % (\n",
        "        classes[c_i], val_classwise_accuracy[c_i]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4mbmrI2m6cc"
      },
      "source": [
        "7.**Visualize test set images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lumxYpO7R0Fk"
      },
      "outputs": [],
      "source": [
        "# get some random training images\n",
        "dataiter = iter(testloader)\n",
        "images = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[:16]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FViai01ZsVeu"
      },
      "source": [
        "8.**Evaluate your final model on the test set**\n",
        "\n",
        "Submit `predictions.npy` to Gradescope to see your model's performance on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLkObaKujdaE"
      },
      "outputs": [],
      "source": [
        "# run inference on the test set\n",
        "predictions = run_secret_test(testloader, net, IS_GPU)\n",
        "# save predictions\n",
        "predictions = np.asarray(predictions)\n",
        "np.save(\"Q1_label_predictions.npy\", predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UupOrBZmj_yU"
      },
      "source": [
        "#**Q2: Surface normal estimation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-LOCbCfTwU9"
      },
      "source": [
        "Download the data (taskonomy_resize_128_public.zip) from google drive using this link (https://drive.google.com/file/d/1EhaGeojCBgoYtsdilTbGd81-95VSgmAP/view?usp=sharing) and upload it to colab.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CQENDOfIvcu"
      },
      "outputs": [],
      "source": [
        "!unzip -qqo /content/taskonomy_resize_128.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geohpotit_Ek"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzpXeiVddIdi"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "from torchvision import models\n",
        "from torchvision.transforms import ToTensor, Normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLe8xge2WCit"
      },
      "outputs": [],
      "source": [
        "# global variable\n",
        "device = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTlJmzl7dR4_"
      },
      "outputs": [],
      "source": [
        "class NormalDataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    Data loader for the Suface Normal Dataset. If data loading is a bottleneck, \n",
        "    you may want to optimize this in for faster training. Possibilities include\n",
        "    pre-loading all images and annotations into memory before training, so as \n",
        "    to limit delays due to disk reads.\n",
        "    \"\"\"\n",
        "    def __init__(self, split=\"train\", data_dir=\"./taskonomy_resize_128_public\"):\n",
        "        assert(split in [\"train\", \"val\"])\n",
        "        split2name = {\n",
        "            \"train\": \"allensville\",\n",
        "            \"val\": \"beechwood\",\n",
        "        }\n",
        "        self.img_dir = os.path.join(data_dir, split2name[split] + \"_rgb\")\n",
        "        self.gt_dir = os.path.join(data_dir, split2name[split] + \"_normal\")\n",
        "        \n",
        "        self.split = split\n",
        "        self.filenames = [\n",
        "            os.path.splitext(os.path.basename(l))[0] for l in glob.glob(self.img_dir + \"/*.png\")\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.filenames[index]\n",
        "        img = Image.open(os.path.join(self.img_dir, filename) + \".png\")\n",
        "        img = np.asarray(img).copy()\n",
        "        gt = Image.open(os.path.join(self.gt_dir, filename.replace(\"_rgb\", \"_normal\")) + \".png\")\n",
        "        gt = np.asarray(gt)\n",
        "\n",
        "        # from rgb image to surface normal\n",
        "        gt = gt.astype(np.float32) / 255\n",
        "        gt = torch.Tensor(np.asarray(gt).copy()).permute((2, 0, 1))\n",
        "        mask = self.build_mask(gt).to(torch.float)\n",
        "\n",
        "        img = ToTensor()(img)\n",
        "        img = Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(img)\n",
        "\n",
        "        # normalize gt\n",
        "        gt = gt * 2 - 1\n",
        "        \n",
        "        return img.contiguous(), gt, mask.sum(dim=0) > 0\n",
        "\n",
        "    @staticmethod\n",
        "    def build_mask(target, val=0.502, tol=1e-3):\n",
        "        target = target.unsqueeze(0)\n",
        "        if target.shape[1] == 1:\n",
        "            mask = ((target >= val - tol) & (target <= val + tol))\n",
        "            mask = F.conv2d(mask.float(), torch.ones(1, 1, 5, 5, device=mask.device), padding=2) != 0\n",
        "            return (~mask).expand_as(target).squeeze(0)\n",
        "\n",
        "        mask1 = (target[:, 0, :, :] >= val - tol) & (target[:, 0, :, :] <= val + tol)\n",
        "        mask2 = (target[:, 1, :, :] >= val - tol) & (target[:, 1, :, :] <= val + tol)\n",
        "        mask3 = (target[:, 2, :, :] >= val - tol) & (target[:, 2, :, :] <= val + tol)\n",
        "        mask = (mask1 & mask2 & mask3).unsqueeze(1)\n",
        "        mask = F.conv2d(mask.float(), torch.ones(1, 1, 5, 5, device=mask.device), padding=2) != 0\n",
        "        return (~mask).expand_as(target).squeeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oMHIGsCdckB"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "#TODO: design your own network here. The expectation is to write from scratch. But it's okay to get some inspiration \n",
        "#from conference paper. The bottom line is that you will not just copy code from other repo\n",
        "##########\n",
        "class MyModel(nn.Module):\n",
        "\n",
        "    def __init__(self): # feel free to modify input paramters\n",
        "        super(MyModel, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, *params): # feel free to modify input paramters\n",
        "        pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6Dtn7yudjC8"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "#TODO: define your loss function here\n",
        "##########\n",
        "class MyCriterion(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Criterion, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, prediction, target, mask):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okJ-P_JGesKq"
      },
      "outputs": [],
      "source": [
        "def simple_train(model, criterion, optimizer, train_dataloader, epoch, **kwargs):\n",
        "    model.train()\n",
        "    # TODO: implement your train loop here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sJiJPb3huXK"
      },
      "outputs": [],
      "source": [
        "########################################################################\n",
        "# TODO: Implement your training cycles, make sure you evaluate on validation \n",
        "# dataset and compute evaluation metrics every so often. \n",
        "# You may also want to save models that perform well.\n",
        "\n",
        "model = MyModel().to(device)\n",
        "criterion = MyCriterion().to(device)\n",
        "optimizer = ?\n",
        "train_dataset = NormalDataset(split='train')\n",
        "train_dataloader = data.DataLoader(train_dataset, batch_size=8, \n",
        "                                    shuffle=True, num_workers=2, \n",
        "                                    drop_last=True)\n",
        "\n",
        "num_epochs = ?\n",
        "for epoch in range(num_epochs):\n",
        "    simple_train(model, criterion, optimizer, train_dataloader, epoch)\n",
        "    # consider reducing learning rate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INjSihbcSIlH"
      },
      "source": [
        "# You do not need to change anything below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA9WZ-Nqh1Ka"
      },
      "outputs": [],
      "source": [
        "########################################################################\n",
        "# Evaluate your result, and report\n",
        "# 1. Mean angular error\n",
        "# 2. Median angular error\n",
        "# 3. Accuracy at 11.25 degree\n",
        "# 4. Accuracy at 22.5 degree\n",
        "# 5. Accuracy at 30 degree\n",
        "# using provided `simple_predict` function.\n",
        "\n",
        "def angle_error(prediction, target):\n",
        "    prediction_error = torch.cosine_similarity(prediction, target)\n",
        "    prediction_error = torch.clamp(prediction_error, min=-1.0, max=1.0)\n",
        "    prediction_error = torch.acos(prediction_error) * 180.0 / np.pi\n",
        "    return prediction_error\n",
        "\n",
        "def simple_predict(split, model):\n",
        "    model.eval()\n",
        "    dataset = NormalDataset(split=split)\n",
        "    dataloader = data.DataLoader(dataset, batch_size=1, shuffle=False, \n",
        "                                 num_workers=2, drop_last=False)\n",
        "    gts, preds, losses = [], [], []\n",
        "    total_normal_errors = None\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(tqdm(dataloader)):\n",
        "            img, gt, mask = batch\n",
        "            img = img.to(device)\n",
        "            gt = gt.to(device)\n",
        "            mask = mask.to(device)\n",
        "\n",
        "            pred = model(img)\n",
        "            loss = (F.l1_loss(pred, gt, reduction=\"none\") * mask.unsqueeze(1)).mean()\n",
        "\n",
        "            gts.append((gt[0].permute((1, 2, 0)).cpu().numpy() + 1) / 2)\n",
        "            preds.append((pred[0].permute((1, 2, 0)).cpu().numpy() + 1) / 2)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            angle_error_prediction = angle_error(pred, gt)\n",
        "            angle_error_prediction = angle_error_prediction[mask > 0].view(-1)\n",
        "            if total_normal_errors is None:\n",
        "                total_normal_errors = angle_error_prediction.cpu().numpy()\n",
        "            else:\n",
        "                total_normal_errors = np.concatenate(\n",
        "                    (total_normal_errors, angle_error_prediction.cpu().numpy())\n",
        "                )\n",
        "\n",
        "    return gts, preds, losses, total_normal_errors\n",
        "\n",
        "val_gts, val_preds, val_losses, val_total_normal_errors = simple_predict('val', model)\n",
        "print(\"Validation loss (L1):\", np.mean(val_losses))\n",
        "print(\"Validation metrics: Mean %.1f, Median %.1f, 11.25deg %.1f, 22.5deg %.1f, 30deg %.1f\" % (\n",
        "    np.average(val_total_normal_errors), np.median(val_total_normal_errors),\n",
        "    np.sum(val_total_normal_errors < 11.25) / val_total_normal_errors.shape[0] * 100,\n",
        "    np.sum(val_total_normal_errors < 22.5) / val_total_normal_errors.shape[0] * 100,\n",
        "    np.sum(val_total_normal_errors < 30) / val_total_normal_errors.shape[0] * 100\n",
        "))\n",
        "\n",
        "# vis validation\n",
        "fig, axs = plt.subplots(ncols=5, nrows=2, figsize=(22, 7))\n",
        "for idx, ax_i in enumerate(axs.T):\n",
        "    ax = ax_i[0]\n",
        "    ax.imshow(val_gts[idx])\n",
        "    ax.axis('off')\n",
        "    ax = ax_i[1]\n",
        "    ax.imshow(val_preds[idx])\n",
        "    ax.axis('off')\n",
        "fig.tight_layout()\n",
        "plt.savefig('vis_valset.pdf', format='pdf', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rBOVQc9CPdW"
      },
      "outputs": [],
      "source": [
        "# Visualization\n",
        "# pick some of your favorite images and put them under `./data/normal_visualization/image`\n",
        "\n",
        "class VisualizationDataset(data.Dataset):\n",
        "    def __init__(self, image_dir=\"./taskonomy_resize_128_public\", image_ext=\".png\"):\n",
        "        self.img_dir = image_dir\n",
        "        self.img_ext = image_ext\n",
        "\n",
        "        self.img_dir = os.path.join(image_dir, \"collierville_rgb\") \n",
        "        \n",
        "        self.image_filenames = [\n",
        "            os.path.splitext(os.path.basename(l))[0] for l in glob.glob(self.img_dir + \"/*\" + image_ext)\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.image_filenames[index]\n",
        "        img = Image.open(os.path.join(self.img_dir, filename) + self.img_ext)\n",
        "        img = np.asarray(img).copy()\n",
        "        img = ToTensor()(img)\n",
        "        img = Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(img)\n",
        "        \n",
        "        return img.contiguous(), filename\n",
        "\n",
        "def simple_vis(model):\n",
        "    model.eval()\n",
        "    dataset = VisualizationDataset(image_dir=\"./taskonomy_resize_128_public\")\n",
        "    dataloader = data.DataLoader(dataset, batch_size=1, shuffle=False, \n",
        "                                 num_workers=2, drop_last=False)\n",
        "    imgs, preds = [], []\n",
        "\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(tqdm(dataloader)):\n",
        "            img, _ = batch\n",
        "            img = img.to(device)\n",
        "\n",
        "            pred = model(img)\n",
        "            imgs.append(\n",
        "                std * img[0].permute((1, 2, 0)).cpu().numpy() + mean\n",
        "            )\n",
        "            preds.append((pred[0].permute((1, 2, 0)).cpu().numpy() + 1) / 2)\n",
        "\n",
        "    return imgs, preds\n",
        "\n",
        "imgs, preds = simple_vis(model)\n",
        "fig, axs = plt.subplots(ncols=5, nrows=2, figsize=(22, 7))\n",
        "for idx, ax_i in enumerate(axs.T):\n",
        "    ax = ax_i[0]\n",
        "    ax.imshow(imgs[idx])\n",
        "    ax.axis('off')\n",
        "    ax = ax_i[1]\n",
        "    ax.imshow(preds[idx])\n",
        "    ax.axis('off')\n",
        "fig.tight_layout()\n",
        "plt.savefig('q2_visualization.pdf', format='pdf', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9vWgNPzN2_Y"
      },
      "outputs": [],
      "source": [
        "# Test your model on the test set, submit the output to gradescope\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def simple_test(model, out_dir):\n",
        "    model.eval()\n",
        "    dataset = VisualizationDataset(image_dir=\"./taskonomy_resize_128_public\")\n",
        "    dataloader = data.DataLoader(dataset, batch_size=1, shuffle=False, \n",
        "                                 num_workers=2, drop_last=False)\n",
        "\n",
        "    saved_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(tqdm(dataloader)):\n",
        "            img, filename = batch\n",
        "            img = img.to(device)\n",
        "\n",
        "            pred = model(img)\n",
        "            saved_predictions.append(pred.cpu())\n",
        "\n",
        "        saved_predictions = torch.cat(saved_predictions, dim=0)\n",
        "        return saved_predictions\n",
        "\n",
        "out_dir = \"Q2_normal_predictions\"\n",
        "saved_predictions = simple_test(model, out_dir)\n",
        "np.save('./Q2_surface_predictions.npy', saved_predictions)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
